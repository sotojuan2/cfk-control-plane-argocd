{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Analyze Existing Gatekeeper Policy",
        "description": "Understand the exact naming convention enforced by the current Gatekeeper policy (`gatekeeper/kafkatopic-naming-template.yaml`). This is crucial for porting the logic to OPA.",
        "details": "The file `gatekeeper/kafkatopic-naming-template.yaml` defines the KafkaTopic naming policy using the following regex: ^demo-topic-[0-9]+$.\n\n- Only names starting with 'demo-topic-' followed by one or more digits are allowed.\n- Valid example: demo-topic-123\n- Invalid examples: demo-topic-test, demo-topic-\n\nThe rule is implemented in Gatekeeper with Rego:\n\nvalid_name(name) {\n  re_match(\"^demo-topic-[0-9]+$\", name)\n}\n\nThe policy rejects any KafkaTopic whose name does not match this pattern and displays the message: 'Kafka topic name \"{name}\" does not follow the required naming pattern'.\n\nThis will serve as the basis for migration to OPA.",
        "testStrategy": "N/A",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Develop OPA Rego Policy for KafkaTopic Naming",
        "description": "Write the Open Policy Agent (OPA) Rego policy (`policies/kafkatopic_naming.rego`) that mirrors the validation logic extracted from the Gatekeeper policy.",
        "details": "The OPA Rego policy was created in `policies/kafkatopic_naming.rego` and correctly enforces the required naming convention for KafkaTopic resources.\n\nValidation results:\n- Manifest with valid name (`demo-topic-1`): No denial message, accepted.\n- Manifest with invalid name (`demo-topic-test`): Denial message returned as expected.\n\nThe policy supports Confluent CRD format and multi-document YAML files.",
        "testStrategy": "Validated using `opa eval` with both valid and invalid KafkaTopic manifests.\n- Valid: No denial message.\n- Invalid: Denial message returned.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Create GitHub Actions Workflow File Structure",
        "description": "Initialize the new GitHub Actions workflow file (`.github/workflows/opa-validation.yml`) to define the CI/CD pipeline for KafkaTopic validation.",
        "details": "Set up the basic YAML structure for the workflow. Define the trigger (on pull requests targeting main/master), and a single job for validation.",
        "testStrategy": "Commit an empty or minimal workflow file and observe if it triggers correctly on a dummy PR.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Implement Code Checkout and Changed Manifest Identification",
        "description": "Add steps to the GitHub Actions workflow to checkout the repository code and identify only the changed Kubernetes manifest files (`.yaml`, `.yml`) within a pull request.",
        "details": "Utilize `actions/checkout@v4` and a suitable action (e.g., `tj-actions/changed-files`) to get a list of modified files. Filter this list to include only relevant manifest files.",
        "testStrategy": "Create a PR with changes to only non-manifest files and verify the workflow correctly identifies no relevant changes. Create a PR with manifest changes and verify the correct files are identified.",
        "priority": "medium",
        "dependencies": [
          3
        ],
        "status": "deferred",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Create User Database Schema",
            "description": "Define and implement the database table structure for storing user information, including credentials and profile data.",
            "dependencies": [],
            "details": "Create a 'users' table using a database migration script. The table should include columns for 'id' (UUID, primary key), 'email' (unique, indexed), 'password_hash' (string), 'created_at', and 'updated_at'. Ensure the password hash column is sufficiently long.",
            "status": "pending",
            "testStrategy": "Run the migration and verify its successful application. Manually inspect the database schema to confirm all columns, constraints, and data types are correct. Write a rollback script and test it."
          },
          {
            "id": 2,
            "title": "Develop User Registration API Endpoint",
            "description": "Create a public API endpoint (e.g., POST /api/v1/register) that allows new users to create an account.",
            "dependencies": [],
            "details": "The endpoint should accept an email and password. It must validate the input (e.g., strong password policy, valid email format), check if the email is already in use, hash the password using bcrypt, and store the new user record in the database. Return a 201 Created status on success.",
            "status": "pending",
            "testStrategy": "Write unit tests for the validation logic. Write integration tests to simulate API calls with valid data, duplicate emails, and invalid passwords. Assert the correct HTTP status codes and database state after each call."
          },
          {
            "id": 3,
            "title": "Implement User Login and JWT Generation",
            "description": "Create an API endpoint (e.g., POST /api/v1/login) for users to authenticate and receive a JSON Web Token (JWT).",
            "dependencies": [],
            "details": "The endpoint will accept an email and password. It should find the user by email, verify the provided password against the stored hash using bcrypt. On successful verification, generate a signed JWT containing the user ID, role, and an expiration claim (e.g., 1 hour).",
            "status": "pending",
            "testStrategy": "Unit test the password verification logic separately. Write integration tests for the login endpoint with correct and incorrect credentials. For successful logins, decode the returned JWT and verify its payload and signature. For failed logins, assert a 401 Unauthorized status."
          },
          {
            "id": 4,
            "title": "Design and Create User Database Schema",
            "description": "Define and implement the database table structure required to store user information, including credentials and profile data.",
            "dependencies": [],
            "details": "Create a 'users' table with columns for id (primary key), username (unique), email (unique), hashed_password, created_at, and updated_at. Use a database migration tool like Alembic or Flyway to manage schema changes.",
            "status": "pending",
            "testStrategy": "Verify the migration runs successfully. Manually inspect the database schema to confirm all columns and constraints are created as specified. Write a unit test to ensure the User model can be instantiated and saved to the database."
          },
          {
            "id": 5,
            "title": "Develop User Registration API Endpoint",
            "description": "Create a public API endpoint (e.g., POST /api/register) that allows new users to sign up for an account.",
            "dependencies": [],
            "details": "The endpoint should accept a username, email, and password. It must validate the input (e.g., password strength, valid email format), check for existing username/email, hash the password using bcrypt, and then store the new user record in the database.",
            "status": "pending",
            "testStrategy": "Write integration tests to cover successful registration, registration with a duplicate username/email, and registration with invalid input (e.g., weak password). Verify that the stored password is not in plain text."
          },
          {
            "id": 6,
            "title": "Implement User Login and Token Generation",
            "description": "Create an API endpoint (e.g., POST /api/login) for users to authenticate and receive an access token.",
            "dependencies": [],
            "details": "The endpoint should accept a username/email and password. It will find the user in the database and compare the provided password with the stored hash. If credentials are valid, generate a JSON Web Token (JWT) containing user identifiers (e.g., user ID) and return it to the client.",
            "status": "pending",
            "testStrategy": "Write integration tests for successful login with correct credentials, failed login with an incorrect password, and failed login for a non-existent user. Verify the structure and signature of the returned JWT."
          }
        ]
      },
      {
        "id": 5,
        "title": "Integrate OPA Validation Step into Workflow",
        "description": "Add a step to the GitHub Actions workflow to execute the OPA Rego policy against the identified `KafkaTopic` resources.",
        "details": "Incorporate a GitHub Marketplace action (e.g., `open-policy-agent/opa-check` or `actions/setup-opa` combined with `opa eval`) to run the `kafkatopic_naming.rego` policy. Ensure the action can process multiple manifest files.",
        "testStrategy": "Run the workflow with a dummy KafkaTopic manifest and verify the OPA action is invoked and processes the input.",
        "priority": "high",
        "dependencies": [
          2,
          4
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Evaluate and Select OPA GitHub Action",
            "description": "Research and compare the recommended GitHub Marketplace actions (`open-policy-agent/opa-check` vs. `actions/setup-opa` with `opa eval`) to determine the most suitable one for the project's needs, focusing on ease of configuration and performance when processing multiple manifest files.",
            "dependencies": [],
            "details": "Comparison:\n\n- open-policy-agent/opa-check:\n  - Simple configuration, supports multiple files, actively maintained.\n  - Best for straightforward validation workflows.\n- actions/setup-opa + opa eval:\n  - Full control, flexible, but requires manual scripting and setup.\n\nDecision: Use `open-policy-agent/opa-check` for this project due to its simplicity and native support for multiple input files.\n\nDocumentation for both actions confirms support for passing a list of files as input.",
            "status": "done",
            "testStrategy": "Documentation reviewed for both actions. Confirmed support for multiple input files. Decision recorded."
          },
          {
            "id": 2,
            "title": "Implement File Discovery Logic in Workflow",
            "description": "Add a preliminary step in the `opa-validation.yml` workflow to identify and list all relevant Kubernetes manifest files that have been changed in the pull request. This list will serve as the input for the OPA validation step.",
            "dependencies": [],
            "details": "Use a tool like `tj-actions/changed-files` or a custom `git diff` script to get a space-separated list of changed YAML/YML files. Store this list in a step output variable for later use.",
            "status": "done",
            "testStrategy": "In a test PR, echo the output variable to the job log to ensure it correctly captures the paths of modified manifest files."
          },
          {
            "id": 3,
            "title": "Add the OPA Validation Step to Workflow YAML",
            "description": "Incorporate the selected OPA GitHub Action as a new step within the validation job in the `.github/workflows/opa-validation.yml` file.",
            "dependencies": [
              "5.1"
            ],
            "details": "Add the `uses:` directive for the chosen action (e.g., `uses: open-policy-agent/opa-check@v1`). Ensure it is placed after the file discovery step.",
            "status": "done",
            "testStrategy": "Commit the change and observe the workflow run to confirm the action is downloaded and initialized without syntax errors in the YAML."
          },
          {
            "id": 4,
            "title": "Configure OPA Action Parameters",
            "description": "Configure the newly added OPA action step with the necessary inputs, including the path to the Rego policy and the list of manifest files to be evaluated.",
            "dependencies": [
              "5.2",
              "5.3"
            ],
            "details": "Use the `with:` block to pass parameters. Set the policy path to `kafkatopic_naming.rego`. Pass the output variable from the file discovery step (subtask 5.2) as the input file list. Specify the Rego query to execute (e.g., `data.kafka.naming.deny`).",
            "status": "done",
            "testStrategy": "Run the workflow with a hardcoded path to a single test manifest to verify the parameter passing mechanism works before using the dynamic list."
          },
          {
            "id": 5,
            "title": "Perform Initial Run with a Dummy Manifest",
            "description": "Create a draft pull request containing a single, simple `KafkaTopic` manifest to perform a basic, low-impact test of the newly integrated OPA validation step.",
            "dependencies": [
              "5.4"
            ],
            "details": "The dummy manifest can be either compliant or non-compliant. The goal is not to test the policy logic itself, but to verify that the OPA action is invoked, correctly receives the manifest as input, and executes the policy against it, producing an exit code.",
            "status": "done",
            "testStrategy": "Observe the workflow logs for the draft PR. Confirm the OPA step runs, logs that it is processing the dummy manifest file, and either passes or fails as expected based on the dummy file's content."
          }
        ]
      },
      {
        "id": 6,
        "title": "Refine OPA Policy and Enhance Error Reporting",
        "description": "Ensure the OPA policy is robust and the workflow provides clear, actionable failure messages when a `KafkaTopic` resource is non-compliant.",
        "details": "Review the Rego policy for any edge cases or missed scenarios. Configure the OPA validation step to output detailed messages, including the specific `KafkaTopic` name and the reason for failure, as required by acceptance criteria.",
        "testStrategy": "Manually trigger the workflow with intentionally malformed KafkaTopic names and verify the error messages are precise and helpful.",
        "priority": "high",
        "dependencies": [
          5
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze Rego Policy for Edge Cases",
            "description": "Systematically review the `kafkatopic_naming.rego` policy to identify potential loopholes, missed scenarios, or edge cases not covered by the initial implementation.",
            "dependencies": [],
            "details": "Examine the policy's logic against various potential `KafkaTopic` manifest structures. Consider scenarios like missing metadata, different API versions, and names that might incorrectly pass or fail the current validation rules. Document all findings.\n<info added on 2025-07-29T13:17:41.978Z>\n**Analysis Findings:**\n\n1.  **Missing Metadata Field**: The policy doesn't check if `input.metadata` exists before trying to access `input.metadata.name`. This could cause undefined variable errors if a KafkaTopic is malformed.\n2.  **Null or Empty Name**: The policy doesn't specifically handle null or empty names. While the regex will fail these cases, a more specific error message would be helpful.\n3.  **Case Sensitivity**: The regex pattern doesn't clarify case sensitivity requirements. A name like \"Demo-Topic-123\" would fail, but the error message doesn't explain why.\n4.  **Multiple Resources in File**: The policy doesn't handle the case where multiple resources are in a single file but only some are KafkaTopics.\n5.  **Error Message Detail**: The error messages could be more helpful by suggesting valid examples and explaining exactly which part of the pattern failed.\n6.  **API Version Check**: There's no validation for the API version of the KafkaTopic resource. Different versions might have different structure/requirements.\n7.  **Input Type Validation**: The policy assumes input is either a single object or an array of objects, but doesn't validate this assumption.\n8.  **Regex Function**: The policy uses `regex.match()` function which might not be available in all OPA environments. The standard is `re_match()`.\n</info added on 2025-07-29T13:17:41.978Z>",
            "status": "done",
            "testStrategy": "Manually review the Rego code and compare it against a checklist of potential edge cases (e.g., empty name, name with special characters, multi-segment names)."
          },
          {
            "id": 2,
            "title": "Update Rego Policy to Address Identified Gaps",
            "description": "Modify the `kafkatopic_naming.rego` file to incorporate the logic required to handle the edge cases and scenarios identified during the analysis phase.",
            "dependencies": [],
            "details": "Refine the regular expressions or add conditional logic to the `deny` rule to make the policy more robust. Ensure the policy correctly handles all identified edge cases while still enforcing the core naming convention.\n<info added on 2025-07-29T13:20:31.371Z>\nThe Rego policy has been updated to address all identified edge cases, making it more robust and user-friendly. Key improvements include:\n- **Input Type Validation**: Added validation to check if the input is a valid object or array.\n- **Missing Metadata Handling**: Added specific rules to detect and report when the `metadata` field is missing.\n- **Missing Name Handling**: Added explicit checks for missing `name` fields within metadata.\n- **Improved Error Messages**: Enhanced messages with more detail about the specific validation failure and included examples of valid names.\n- **Specific Validation Errors**: A new helper function, `get_validation_error()`, provides detailed information about exactly which part of the name validation failed (e.g., empty name, wrong prefix, missing numbers).\n- **Fixed Regex Function**: Replaced `regex.match()` with the standard `re_match()` function for better compatibility.\n- **Better Array Handling**: Improved error messages for array inputs to include the index of the invalid KafkaTopic.\n- **Comprehensive Error Cases**: Added specific error handling for all identified edge cases.\n</info added on 2025-07-29T13:20:31.371Z>",
            "status": "done",
            "testStrategy": "Use `opa eval` with test manifests specifically designed to trigger the previously identified edge cases and confirm the policy now behaves as expected."
          },
          {
            "id": 3,
            "title": "Refactor `deny` Rule for Dynamic Error Message Generation",
            "description": "Modify the `deny` rule in `kafkatopic_naming.rego` to produce a detailed, dynamic failure message that includes the resource name and the specific reason for non-compliance.",
            "dependencies": [],
            "details": "Change the `deny` rule to return a formatted string. Use `sprintf` or string concatenation to construct a message like: 'KafkaTopic \"{resource_name}\" is non-compliant. Reason: {failure_reason}'.\n<info added on 2025-07-29T13:37:00.300Z>\nThis subtask was completed as part of the comprehensive policy update in subtask 6.2. The implementation includes a dedicated `get_validation_error()` helper function to provide specific failure reasons. The `deny` rule now uses `sprintf` to generate context-aware, detailed error messages that include the resource name, the specific reason for failure (e.g., \"must end with one or more digits\"), and an example of a valid name, providing highly specific and actionable feedback.\n</info added on 2025-07-29T13:37:00.300Z>",
            "status": "done",
            "testStrategy": "Run `opa eval` against an invalid manifest and inspect the JSON output to ensure the `deny` field contains the complete, correctly formatted error message."
          },
          {
            "id": 4,
            "title": "Configure GitHub Actions Step to Capture and Display OPA Errors",
            "description": "Update the `opa-validation.yml` workflow to correctly parse the output from the OPA evaluation and surface the detailed error messages in the GitHub Actions run logs.",
            "dependencies": [],
            "details": "Modify the script in the validation step to check if the OPA evaluation produced any `deny` messages. If denials exist, print each message to standard error and fail the workflow step with a non-zero exit code.\n<info added on 2025-07-29T13:38:48.989Z>\nUpon review of the `.github/workflows/opa-validation.yml` file, it was determined that no changes were required. The existing implementation already correctly captures and displays OPA denial messages. The script uses `opa eval --fail` to detect a failure, then explicitly runs a second `opa eval` command against the `deny` rule to print the detailed, dynamic error messages. The workflow correctly sets a failure flag and exits with a non-zero status code, ensuring that the enhanced error messages from the refactored Rego policy are surfaced in the GitHub Actions logs as intended.\n</info added on 2025-07-29T13:38:48.989Z>",
            "status": "done",
            "testStrategy": "Run the validation script locally, pointing it to the OPA policy and an invalid manifest, and verify it prints the error message and exits with a status of 1."
          },
          {
            "id": 5,
            "title": "Perform Local End-to-End Validation of Error Reporting",
            "description": "Create a comprehensive set of test `KafkaTopic` manifests (both valid and invalid) and run the entire local validation script to confirm the refined policy and error reporting work together correctly.",
            "dependencies": [],
            "details": "Create several YAML files containing `KafkaTopic` resources that violate the naming policy in different ways. Execute the validation script against these files and verify that for each violation, the correct, specific error message is displayed.\n<info added on 2025-07-29T13:54:14.852Z>\nValidation testing is complete. The OPA policy correctly validates single-document YAML files and provides specific error messages for the following verified failures:\n*   Empty name: \"KafkaTopic name '' is invalid: name cannot be empty\"\n*   Wrong prefix: \"KafkaTopic name 'wrong-prefix-123' is invalid: must start with 'demo-topic-'\"\n*   Wrong suffix: \"KafkaTopic name 'demo-topic-abc' is invalid: must end with one or more digits after 'demo-topic-'\"\n*   Missing metadata: \"KafkaTopic is missing required 'metadata' field\"\n\nA comprehensive test suite and an automation script (`validate_kafkatopics.sh`) have been created.\n\n**LIMITATION DISCOVERED:** The current OPA validation process only evaluates the *first* document in a multi-document YAML file; subsequent documents are ignored. This does not affect the GitHub Actions workflow, which processes files individually, but it should be documented as a known limitation for users performing local validation on multi-document files.\n</info added on 2025-07-29T13:54:14.852Z>",
            "status": "done",
            "testStrategy": "Execute the local validation script against a directory of test manifests and confirm that the script fails and the output log contains precise error messages for each non-compliant resource."
          }
        ]
      },
      {
        "id": 7,
        "title": "Test Workflow with Compliant Resources (Positive Case)",
        "description": "Perform end-to-end testing of the GitHub Actions workflow by creating a pull request with valid `KafkaTopic` names to ensure it passes correctly.",
        "details": "Create a new branch, add a Kubernetes manifest containing one or more `KafkaTopic` resources that fully comply with the defined naming convention. Open a pull request and verify the workflow completes successfully.",
        "testStrategy": "Create a test PR with valid KafkaTopic manifests. Observe the GitHub Actions workflow run and confirm it passes.",
        "priority": "high",
        "dependencies": [
          6
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Prepare Test Environment and Feature Branch",
            "description": "Set up the local development environment and create a new Git branch for the test.",
            "dependencies": [],
            "details": "Steps:\n1. Ensure local Git repository is synchronized with the `main` or `master` branch (`git checkout main && git pull`).\n2. Create a new feature branch for this test (`git checkout -b feature/test-compliant-kafka-topic`).\nAcceptance Criteria: A new Git branch named `feature/test-compliant-kafka-topic` is created and checked out locally, reflecting the latest state of the main branch.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Create Kubernetes Manifest with Compliant KafkaTopic",
            "description": "Generate a Kubernetes manifest file containing one or more `KafkaTopic` resources that strictly adhere to the defined naming convention (`^demo-topic-[0-9]+$`).",
            "dependencies": [
              "7.1"
            ],
            "details": "Steps:\n1. Create a new directory `test-resources/` if it doesn't exist.\n2. Inside `test-resources/`, create a new YAML file, e.g., `compliant-kafka-topic.yaml`.\n3. Add a `KafkaTopic` resource definition to `compliant-kafka-topic.yaml` with `metadata.name` matching the `^demo-topic-[0-9]+$` regex (e.g., `name: demo-topic-123`).\n4. Ensure the manifest is syntactically valid Kubernetes YAML.\nAcceptance Criteria: A file `test-resources/compliant-kafka-topic.yaml` exists, containing at least one `KafkaTopic` resource whose `metadata.name` field is `demo-topic-` followed by one or more digits.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Commit Compliant Resources and Open Pull Request",
            "description": "Commit the newly created compliant `KafkaTopic` manifest to the feature branch and open a pull request targeting the `main` or `master` branch.",
            "dependencies": [
              "7.2"
            ],
            "details": "Steps:\n1. Add the `test-resources/compliant-kafka-topic.yaml` file to the Git staging area (`git add test-resources/compliant-kafka-topic.yaml`).\n2. Commit the changes with a descriptive message (`git commit -m \"feat: Add compliant KafkaTopic for workflow positive test\"`).\n3. Push the feature branch to the remote repository (`git push origin feature/test-compliant-kafka-topic`).\n4. Navigate to GitHub and open a new pull request from `feature/test-compliant-kafka-topic` to `main` (or `master`).\nAcceptance Criteria: A pull request is successfully opened on GitHub, originating from `feature/test-compliant-kafka-topic` and targeting `main`, containing the `compliant-kafka-topic.yaml` file.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Verify GitHub Actions Workflow Execution and Success",
            "description": "Monitor the GitHub Actions workflow triggered by the pull request and confirm that it completes successfully without any validation errors.",
            "dependencies": [
              "7.3"
            ],
            "details": "Steps:\n1. Navigate to the \"Actions\" tab in the GitHub repository for the opened pull request.\n2. Locate the workflow run associated with the `opa-validation.yml` workflow.\n3. Observe the workflow progress, ensuring all steps, particularly the OPA validation step, execute and pass.\n4. Review the workflow logs to confirm no errors or unexpected warnings are reported by the OPA validation.\nAcceptance Criteria: The GitHub Actions workflow run for the pull request completes with a \"Success\" status, and the OPA validation step explicitly indicates that the `KafkaTopic` resources are compliant.\n<info added on 2025-07-29T16:42:44.254Z>\n✅ **Workflow Verification Completed Successfully**\n\n**GitHub Actions Workflow Run Details:**\n- Workflow Run ID: 16600732912\n- Status: ✅ **SUCCESS** \n- Duration: 7 seconds\n- Date: July 29, 2025\n\n**Validation Results:**\n- ✅ All KafkaTopic resources passed OPA validation\n- ✅ 4 YAML files were successfully validated:\n  - test-resources/compliant-kafka-topic.yaml\n  - test-resources/multiple-compliant-topics.yaml\n  - data/CP/topics.yml\n  - data/CC/topicsCloud.yml\n\n**Workflow Steps Executed:**\n1. ✅ Repository checkout completed\n2. ✅ Changed files detection completed (found 4 relevant YAML files)\n3. ✅ OPA setup completed (version 0.70.0)\n4. ✅ KafkaTopic validation completed with **NO ERRORS**\n\n**Key Validation Output:**\n```\n✅ All KafkaTopic resources passed validation\nNo policy violations found\n```\n\n**Acceptance Criteria Verification:**\n- [x] GitHub Actions workflow run completed with \"Success\" status\n- [x] OPA validation step executed successfully \n- [x] No errors or warnings reported by OPA validation\n- [x] All compliant KafkaTopic resources were validated successfully\n\nThe positive case testing has been **successfully completed**. The workflow correctly validates compliant KafkaTopic resources and allows them through the CI/CD pipeline.\n</info added on 2025-07-29T16:42:44.254Z>",
            "status": "done",
            "testStrategy": "Observe the GitHub Actions workflow run for the opened pull request and confirm its successful completion, specifically verifying the OPA validation step passes as expected for compliant resources."
          },
          {
            "id": 5,
            "title": "Document Test Results and Clean Up Test Branch",
            "description": "Record the outcome of the test, including relevant links or screenshots, and clean up the test branch and resources.",
            "dependencies": [
              "7.4"
            ],
            "details": "Steps:\n1. Document the successful test run, including a link to the specific GitHub Actions workflow run and a screenshot of the successful status.\n2. Note any specific observations or details from the workflow logs.\n3. Close the pull request on GitHub (if not merged).\n4. Delete the remote feature branch (`git push origin --delete feature/test-compliant-kafka-topic`).\n5. Delete the local feature branch (`git branch -D feature/test-compliant-kafka-topic`).\n6. Remove the `test-resources/compliant-kafka-topic.yaml` file locally.\nAcceptance Criteria: The test results are clearly documented (e.g., in a test report or task comment). The `feature/test-compliant-kafka-topic` branch is deleted from both local and remote repositories, and the test manifest file is removed.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 8,
        "title": "Test Workflow with Non-Compliant Resources (Negative Case)",
        "description": "Perform end-to-end testing of the GitHub Actions workflow by creating a pull request with invalid `KafkaTopic` names to ensure it fails as expected.",
        "details": "Create a new branch, add a Kubernetes manifest containing one or more `KafkaTopic` resources that violate the defined naming convention. Open a pull request and verify the workflow fails, providing clear error messages.",
        "testStrategy": "Create a test PR with invalid KafkaTopic manifests. Observe the GitHub Actions workflow run and confirm it fails with the expected error messages.",
        "priority": "high",
        "dependencies": [
          6
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Test Branch for Negative Case",
            "description": "Create a new Git branch specifically for testing the negative case of the KafkaTopic naming convention workflow. This branch will house the non-compliant manifest.",
            "dependencies": [],
            "details": "From the `main` or `master` branch, create a new branch (e.g., `feature/test-invalid-kafka-topic`).",
            "status": "done",
            "testStrategy": "Verify the new branch is created successfully and is based on the correct parent branch."
          },
          {
            "id": 2,
            "title": "Develop Non-Compliant KafkaTopic Manifest",
            "description": "Design and create a Kubernetes manifest file (`.yaml` or `.yml`) that contains one or more `KafkaTopic` resources intentionally violating the defined naming convention.",
            "dependencies": [
              "8.1"
            ],
            "details": "Identify specific naming convention rules (e.g., no hyphens, must start with a letter, max length) and create `KafkaTopic` resources that break these rules. Examples: `my_invalid_topic`, `123topic`, `topic-too-long-name-that-exceeds-the-limit`.\n<info added on 2025-07-30T13:15:17.561Z>\nCorrection: To ensure better compatibility with the OPA validation step, the implementation was changed from a single multi-document YAML file to three separate files. Each file contains a single `KafkaTopic` manifest designed to violate the established naming convention (`^demo-topic-[0-9]+$`) in a specific way:\n1.  `invalid-prefix-topic.yaml`: Contains the name \"invalid-topic-123\" to test for an incorrect prefix.\n2.  `invalid-suffix-topic.yaml`: Contains the name \"demo-topic-test\" to test for a non-numeric suffix.\n3.  `invalid-empty-suffix-topic.yaml`: Contains the name \"demo-topic-\" to test for a missing numeric suffix.\n</info added on 2025-07-30T13:15:17.561Z>",
            "status": "done",
            "testStrategy": "Manually inspect the created manifest file to ensure it clearly contains invalid `KafkaTopic` names according to the established rules."
          },
          {
            "id": 3,
            "title": "Commit and Push Invalid Manifest to Test Branch",
            "description": "Add the newly created Kubernetes manifest with non-compliant `KafkaTopic` resources to the Git repository, commit it, and push the changes to the dedicated test branch.",
            "dependencies": [
              "8.1",
              "8.2"
            ],
            "details": "Use `git add <manifest_file>`, `git commit -m \"feat: Add invalid KafkaTopic manifest for negative test\"`, and `git push origin <test_branch_name>`.",
            "status": "done",
            "testStrategy": "Verify the commit appears in the branch history and the file is present on the remote repository."
          },
          {
            "id": 4,
            "title": "Open Pull Request for Negative Case Validation",
            "description": "Open a new pull request from the test branch (containing the invalid manifest) targeting the `main` or `master` branch to trigger the GitHub Actions workflow.",
            "dependencies": [
              "8.3"
            ],
            "details": "Navigate to the GitHub repository, select the test branch, and create a new pull request. Provide a clear title (e.g., \"Test: Negative KafkaTopic Naming Convention\") and description.",
            "status": "done",
            "testStrategy": "Verify the pull request is successfully created and the associated GitHub Actions workflow run is initiated."
          },
          {
            "id": 5,
            "title": "Validate Workflow Failure and Error Messages",
            "description": "Monitor the GitHub Actions workflow run triggered by the pull request and confirm that it fails as expected due to the non-compliant `KafkaTopic` names. Additionally, verify that the error messages provided by the workflow are clear, informative, and accurately indicate the naming violations.",
            "dependencies": [
              "8.4"
            ],
            "details": "Access the GitHub Actions tab for the pull request, review the workflow run logs, specifically looking for the OPA validation step's output. Confirm the workflow status is 'failed' and the logs contain specific error messages detailing which `KafkaTopic` names are invalid and why.",
            "status": "done",
            "testStrategy": "Screenshot or record the workflow run status and the relevant error messages from the logs to document the successful negative test case."
          }
        ]
      },
      {
        "id": 9,
        "title": "Decommission Gatekeeper Policy and Constraint",
        "description": "Safely remove the old `kafkatopic-naming-template.yaml` file from the repository and its corresponding `Constraint` from the Kubernetes cluster.",
        "details": "Coordinate with the cluster operations team to ensure the `Constraint` is removed from the cluster. Delete the `kafkatopic-naming-template.yaml` file from the `cfk-control-plane-argocd` repository.",
        "testStrategy": "Verify the Gatekeeper policy is no longer active in the cluster. Attempt to deploy a non-compliant KafkaTopic directly to the cluster (outside ArgoCD) to confirm Gatekeeper no longer blocks it.",
        "priority": "medium",
        "dependencies": [
          7,
          8
        ],
        "status": "in-progress",
        "subtasks": [
          {
            "id": 1,
            "title": "Coordinate Constraint Removal with Cluster Operations",
            "description": "Formally request and schedule the deletion of the active Gatekeeper Constraint from the Kubernetes cluster with the operations team.",
            "dependencies": [],
            "details": "Create a ticket or follow the established change management process to request the removal of the Constraint enforcing the `kafkatopic-naming-template`. Provide the exact name and namespace of the resource to be deleted.\n<info added on 2025-07-30T14:16:22.119Z>\nIniciando coordinación con equipo de operaciones del cluster:\n\nANÁLISIS DEL CONSTRAINT ACTUAL:\n- Archivo: gatekeeper/kafkatopic-naming-template.yaml\n- Tipo de recurso: ConstraintTemplate y posiblemente un Constraint asociado\n- Política a desactivar: Validación de nombres de KafkaTopic con patrón ^demo-topic-[0-9]+$\n\nSOLICITUD PARA EQUIPO DE OPERACIONES:\n1. Identificar y listar todos los Constraints activos relacionados con kafkatopic-naming\n2. Remover el/los Constraint(s) del cluster de Kubernetes \n3. Verificar que no hay otras dependencias o recursos relacionados\n\nJUSTIFICACIÓN:\n- Nueva validación OPA implementada y probada exitosamente\n- Migración completa del sistema de validación de Gatekeeper a OPA\n- Reducción de complejidad en el cluster\n\nPRÓXIMOS PASOS:\n- Esperar confirmación del equipo de operaciones\n- Proceder con la eliminación del archivo del repositorio una vez confirmada la coordinación\n</info added on 2025-07-30T14:16:22.119Z>",
            "status": "pending",
            "testStrategy": "Confirm that the request has been received and scheduled by the cluster operations team."
          },
          {
            "id": 2,
            "title": "Create Pull Request to Remove Policy File from Repository",
            "description": "Delete the `kafkatopic-naming-template.yaml` file from the `cfk-control-plane-argocd` repository via a pull request.",
            "dependencies": [],
            "details": "Create a new branch, remove the `gatekeeper/kafkatopic-naming-template.yaml` file, and submit a pull request. The PR description must reference Task 9 and explain the policy is being decommissioned in favor of the new OPA validation workflow.\n<info added on 2025-07-30T14:43:07.071Z>\nThe branch `feature/remove-gatekeeper-policy` has been created and the `gatekeeper/kafkatopic-naming-template.yaml` file has been deleted. The changes were pushed to the remote repository under commit `0ab25a2`. The commit message explains the policy is being decommissioned in favor of the new OPA validation workflow and references this task. The pull request is ready to be created using the following link: https://github.com/sotojuan2/cfk-control-plane-argocd/pull/new/feature/remove-gatekeeper-policy\n</info added on 2025-07-30T14:43:07.071Z>",
            "status": "in-progress",
            "testStrategy": "Ensure the pull request passes all status checks and is approved by code owners."
          },
          {
            "id": 3,
            "title": "Confirm Deletion of Gatekeeper Constraint from Cluster",
            "description": "Follow up with the cluster operations team to ensure the Gatekeeper Constraint has been successfully deleted from the cluster.",
            "dependencies": [
              "9.1"
            ],
            "details": "Verify the completion of the ticket or change request from subtask 1. If possible, use `kubectl get constraint <constraint-name>` to confirm the resource no longer exists.",
            "status": "pending",
            "testStrategy": "Obtain explicit confirmation (e.g., a closed ticket) from the operations team that the deletion command was executed successfully."
          },
          {
            "id": 4,
            "title": "Verify Policy Decommissioning with a Non-Compliant Resource",
            "description": "Directly apply a `KafkaTopic` manifest to the cluster that violates the old naming policy to confirm it is no longer blocked by Gatekeeper.",
            "dependencies": [
              "9.3"
            ],
            "details": "Create a temporary YAML file for a KafkaTopic with a non-compliant name (e.g., `name: invalid-topic-name`). Use `kubectl apply -f` to attempt to create it in the cluster. The resource creation must succeed.",
            "status": "pending",
            "testStrategy": "The `kubectl apply` command should return a success message. Follow up with `kubectl get kafkatopic invalid-topic-name` to confirm its creation. Clean up the test resource afterwards."
          }
        ]
      },
      {
        "id": 10,
        "title": "Update Documentation (README.md)",
        "description": "Update the `README.md` file in the `cfk-control-plane-argocd` repository to reflect the new `KafkaTopic` validation process.",
        "details": "Add a section explaining the shift-left validation using GitHub Actions and OPA. Provide instructions on how developers can check policy compliance and interpret workflow failures.",
        "testStrategy": "Review the updated `README.md` for clarity, accuracy, and completeness regarding the new validation process.",
        "priority": "low",
        "dependencies": [
          9
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-29T08:08:26.040Z",
      "updated": "2025-07-30T14:34:47.497Z",
      "description": "Tasks for master context"
    }
  }
}